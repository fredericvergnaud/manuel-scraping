# Les enjeux juridiques et éthiques du scraping {#sec-introduction-enjeux-juridiques-ethiques .unnumbered}

MODIFIE 2

Scraping : méthode facile à mettre en place + facilité d'accès / gratuité d'accès aux données web + automatisation du processus (robotisation) peut donner l'impression d'une méthode « magique, miraculeuse », qu'on ne contrôle pas trop, autonome, sentiment de puissance et d'impunité (voir éthique du scraping) ...

Importance du terme « scraping à des fins de recherche » est bien sûr important ici : on se focalise sur le scraping de données dans une finalité de recherche, ce qui a des conséquences sur la réutilisation de ces données (voir infra).

Mais pose immédiatement après la question de la légalité : a-t-on le droit d'extraire des données librement consultables sur le web ? car on sent instinctivement une sorte de dépouillement, de données que l'on dérobe à l'insu de son propriétaire.

Mais justement, qui est le propriétaire de ces données ? Le propriétaire de la base de données qui héberge les données à extraire ? La personne qui est à la source de ces données ?

Comme nous le verrons dans la partie B de ce chapitre, les données que nous consultons via Internet et notre navigateur web ne sont pas situées sur notre ordinateur. Elles sont en réalité stockées au sein d'une base de données qui est hébergée sur un ordinateur que l'on appelle un serveur. Pour qu'elles apparaissent sur notre écran, nous effectuons des requêtes, c'est à dire des demandes, sur cette base de données. Ainsi, le serveur qui héberge les données consultées, et donc la base de données qui les abrite, peut être situé en France, aussi bien que dans un autre pays, qu'il soit européen ou non.

A partir de la fin des années 90, le droit est très clair sur le sujet et défini une protection pour ce que l'on appelle les producteurs de base de données. Cette loi garantie de protéger (i) les données elles-mêmes, par le droit d'auteur, et (ii) la base de données, par le droit sui generis, qui protège l'investissement consenti pour la création et la gestion de la base de données. Cette protection des producteurs de bases de données relève alors, en France, du Code de la Propriété Intellectuelle (CPI) (article L112-3 du Code de la propriété intellectuelle). Ainsi, si l'on souhaite scraper des données tout en respectant le cadre juridique imposé par la loi, il faut obtenir en premier lieu le consentement du propriétaire de la base qui héberge ces données, mais également l'autorisation de l'auteur des données que l'on souhaite extraire si celles-ci relèvent du droit d'auteur, ce qui est notamment le cas de certains textes, images ou vidéos. Dans le cas contraire, le scraping « sauvage » vous expose à un risque juridique important, que vous ne pouvez contourner qu'en négociant avec le producteur de la base de données et/ou l'auteur des données un accès privilégié via une API (cf. Chapitre ...). Cette méthode pouvait malheureusement se révéler fastidieuse, coûteuse et non forcément couronnée de succès (Bastin, Tubaro 2018).

En 2016 nait un espoir avec la loi Lemaire, dite « Loi pour une République Numérique », qui intègre une exception au droit des producteurs de bases de données et au droit d'auteur en donnant la possibilité de recourir à la fouille de textes et de données (« Text and Data Mining » - TDM) lorsque ceux-ci se trouvent adossés à des « écrits scientifiques ». Très limitée dans sa portée, les décrets d'application n'ont cependant jamais été édictés suite à un avis défavorable du Conseil d'État ([Ouvrir la Science](https://www.ouvrirlascience.fr/la-fouille-de-textes-et-de-donnees-a-des-fins-de-recherche-une-pratique-confirmee-et-desormais-operationnelle-en-droit-francais/), 16/12/2021).

Parallèlement aux textes de loi, l'entrée en application du nouveau règlement général européen sur la protection des données personnelles (RGPD) en 2018 durcit un peu plus les conditions d'accès de la recherche aux données en ligne et font d'elle une sorte de « victime collatérale » des abus d'exploitation des plateformes de réseaux sociaux (Bastin, Tubaro, 2018). Il est alors strictement interdit d'extraire des données numériques permettant une identification aisée d'une personne réelle, même si certaines dérogations sont accordées sous certaines conditions par la CNIL.

## Novembre 2021 : le TDM à des fins de recherche est confirmé et opérationnel en droit français

C'est en 2019 que le droit français adopte la directive européenne sur le droit d'auteur et les droits voisins dans le marché unique numérique, qui reprend à son tour des dispositions relatives à la méthode du TDM, définie comme « la mise en œuvre d'une technique d'analyse automatisée de textes et de données sous forme numérique afin d'en dégager des informations, notamment des constantes, des tendances et des corrélations » (Ouvrir la Science ! consulté le 05/04/2022). La France a traduit cette directive dans son ordonnance du 24 novembre 2021, qui permet de « reproduire des contenus protégés par des droits de propriété intellectuelle dans le but de conduire des activités de fouille à des fins de recherche scientifique, sans avoir à recueillir d'autorisation préalable des "titulaires de droits" (les producteurs de bases de données, les propriétaires des textes et/ou des données ciblées par le TDM : entreprises, éditeurs,...) ou à obtenir des licences de leur part » (Ouvrir la Science ! consulté le 05/04/2022). D'un point de vue juridique, il s'agit donc d'une exception au droit de la propriété intellectuelle et au droit sui generis des producteurs de bases de données. Cette exception entraine un changement important de paradigme en rendant autorisé ce qui ne l'était pas précédemment : le scraping de données à des fins de recherche, qu'il concerne tout type d'objets tels que des textes, des images, des sons ou des vidéos, est pleinement autorisé par cette ordonnance du droit français, et ce sans autorisations ou licences préalables.

## Les conditions à respecter : accès licite, intégrité et sécurité, conformité aux autres textes en vigueur (RGPD ...etc)

Extraire des données du web à des fins de recherche nécessite tout de même de se conformer à 3 conditions. La première est que l'accès aux données doit être « licite ». Les données disponibles en accès libre sur Internet rentrent dans ce cas de figure si elles sont diffusées d'une manière qui est permise par la loi. Les 2 autres conditions d'intégrité et de sécurité sont quant à elles mises en œuvre par les titulaires de droits, c'est à dire les hébergeurs de contenus. La loi les autorise à appliquer « des mesures proportionnées et nécessaires afin d'assurer la sécurité et l'intégrité des réseaux et des bases de données dans lesquelles les œuvres sont hébergées ». De la même manière que durant la période pré-TDM, vous devrez alors négocier avec les ayants-droits un accès spécifique via des système d'authentification ou des API d'interrogation développées spécialement. Enfin, l'exception TDM ne dispense pas de respecter la RGPD. Comme nous l'avons vu précédemment, un scraping de données personnelles permettant l'identification de la personne réelle devra se conformer strictement au RGPD : demande de consentement et anonymisation notamment.

## La réutilisation des données scrapées à des fins de recherche

Voir si <https://hal.archives-ouvertes.fr/hal-01908766> est intéressant ?

Lionel Maurel, juriste et conservateur de bibliothèque, lors d'un séminaire sur la propriété des données de recherche (MATE-SHS) La loi pour une République numérique (voir supra) considère les données produites par la recherche comme des informations publiques, et a établi pour leur diffusion et leur réemploi un principe d'ouverture par défaut, ainsi qu'une libre réutilisation. Cependant, comme tout principe en droit, le principe d'ouverture et de réutilisation comporte des exceptions, et les données extraites du web dans le cadre de la recherche n'y échappent pas. Ainsi, la réutilisation des données post-scraping s'accompagne de mesures relatives notamment au droit de propriété intellectuelle, comme les droits d'auteur, ou à la protection des données personnelles ou de la vie privée. De même, les secrets/objets protégés par des brevets, ou, dans le cadre de la recherche partenariale, le droit de producteurs de bases de données dont bénéficient les entreprises, les accords de consortiums, les contrats ...etc, devront être respectés lors d'une éventuelle diffusion ou réutilisation post-scraping.

## Éthique -- bonnes pratiques du scraping

L'ordonnance de novembre 2021 ouvre la voie à une intensification de la méthode du scraping pour la recherche. Ce n'est pas pour autant qu'il ne faut pas respecter une certaine éthique / bonne pratique. Ethique pre-scraping, per-scraping et post-scraping Pre-scraping : demander le consentement ; rapport humain est à privilégier ; communiquer sur l'enquête : pourquoi, comment, avec qui, quand ...etc; renseigner le user-agent avec son nom, et lien vers page web de son enquête <https://www.euppublishing.com/doi/full/10.3366/ijhac.2016.0162>; se poser la question de l'existence d'une API et la privilégier si elle existe; lire le fichier robots.txt accessible à la racine du site /robots.txt si il existe; lire les conditions générales d'utilisation (CGU) ou terms of service (TOS) quand elles existent ; Voir aussi <https://www.euppublishing.com/doi/full/10.3366/ijhac.2016.0162> (tableau de recommandations en fonction du type d'accès)

Per-scraping : ne pas surcharger la bande passante du serveur, risque de bannissement de l'adresse IP de manière temporaire ou définitive, mais aussi pour en assurer une utilisation optimale pour les autres utilisateurs car un trafic intense peut perturber l'infrastructure du serveur (ralentissement, contenus rendus indisponibles) : limiter la rapidité de la navigation en ajoutant un temps de latence entre les requêtes ; permet aussi de ne pas être pris pour un hacker ; scraper en dehors des heures de pointe -- la nuit, en fonction des décalages horaire ;

Post-scraping : respect RGPD et différents droits vus précédemment (Le respect de la vie privée : on l'a déjà vu, l'extraction de données personnelles permettant la reconnaissance d'une personne physique est très encadrée par le RGPD : anonymisation, consentement. ); citer les sources ; décrire la méthode utilisée pour constituer une base de connaissances sur le sujet ;
